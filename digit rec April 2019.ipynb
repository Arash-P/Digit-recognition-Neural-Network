{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-Set up and preprocessing\n",
    "    Reshape from 1D to 2D and normalize the training data\n",
    "    Binarizer encoding the training data\n",
    "    Splitting data into training and valdiation set\n",
    "    \n",
    "2-Building a CNN model\n",
    "\n",
    "3-Training a CNN model\n",
    "    Selecting optimizer and setting initial learning rate\n",
    "    Specifying  learning rate reduction and setting checkpoints\n",
    "    Data augmentation\n",
    "    Setting number of epochs and training/validation batch sizes\n",
    "    Fitting the model\n",
    "    \n",
    "4-Making predictions on the test data\n",
    "    Importing and Reshaping the test data from 1D to 2D\n",
    "    Predicting and saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apour\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, BatchNormalization, Dropout\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers.convolutional import *\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Set up and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape from 1D to 2D and normalize the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = train[:, 1:].reshape(train.shape[0],28,28, 1).astype( 'float32' )\n",
    "X_train = trainX/(np.amax(train)-np.amin(train))\n",
    "X_train=np.array(X_train)\n",
    "\n",
    "y_train = train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binarizer encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into training and valdiation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "random_seed = 2\n",
    "# Split the train and the validation set for the fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainX, validX, trainY, validY = train_test_split(X_train, y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4200, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14a62b70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num= random.randint(1,trainX.shape[0])\n",
    "print(trainY[num-1])\n",
    "plt.matshow(trainX[num-1,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Building a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,755,722\n",
      "Trainable params: 1,755,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(5,5), activation='relu',padding='same', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32,kernel_size=(5,5), activation='relu',padding='same'))\n",
    "model.add(Conv2D(32,kernel_size=(5,5), activation='relu',padding='same'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', data_format=None))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64,kernel_size=(3,3), activation='relu',padding='same'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3), activation='relu',padding='same'))\n",
    "model.add(Conv2D(64,kernel_size=(3,3), activation='relu',padding='same'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid', data_format=None))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Training the CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting optimizer and setting initial learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-8, decay=0.0)\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying  learning rate reduction and setting checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3, min_lr=0.00001,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint1 =keras.callbacks.ModelCheckpoint( 'nextLoss.h5', monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "checkpoint2 =keras.callbacks.ModelCheckpoint( 'nextValid_acc.h5', monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=10, zoom_range=0.1,width_shift_range=0.1,  height_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting number of epochs and training/validation batch sizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=100\n",
    "TBS=200\n",
    "VBS=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 811s - loss: 0.7410 - acc: 0.7550 - val_loss: 0.0866 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.74096, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97238, saving model to nextValid_acc.h5\n",
      "Epoch 2/100\n",
      " - 808s - loss: 0.1849 - acc: 0.9457 - val_loss: 0.0531 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00002: loss improved from 0.74096 to 0.18488, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.97238 to 0.98500, saving model to nextValid_acc.h5\n",
      "Epoch 3/100\n",
      " - 840s - loss: 0.1220 - acc: 0.9654 - val_loss: 0.0810 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00003: loss improved from 0.18488 to 0.12200, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.98500\n",
      "Epoch 4/100\n",
      " - 837s - loss: 0.0947 - acc: 0.9723 - val_loss: 0.0392 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00004: loss improved from 0.12200 to 0.09469, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.98500 to 0.98762, saving model to nextValid_acc.h5\n",
      "Epoch 5/100\n",
      " - 783s - loss: 0.0857 - acc: 0.9761 - val_loss: 0.0243 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00005: loss improved from 0.09469 to 0.08575, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.98762 to 0.99357, saving model to nextValid_acc.h5\n",
      "Epoch 6/100\n",
      " - 860s - loss: 0.0744 - acc: 0.9781 - val_loss: 0.0270 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00006: loss improved from 0.08575 to 0.07440, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.99357\n",
      "Epoch 7/100\n",
      " - 810s - loss: 0.0689 - acc: 0.9806 - val_loss: 0.0267 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00007: loss improved from 0.07440 to 0.06887, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.99357\n",
      "Epoch 8/100\n",
      " - 783s - loss: 0.0618 - acc: 0.9819 - val_loss: 0.0226 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00008: loss improved from 0.06887 to 0.06184, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99357\n",
      "Epoch 9/100\n",
      " - 832s - loss: 0.0459 - acc: 0.9868 - val_loss: 0.0214 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00009: loss improved from 0.06184 to 0.04586, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99357\n",
      "Epoch 10/100\n",
      " - 860s - loss: 0.0425 - acc: 0.9875 - val_loss: 0.0203 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00010: loss improved from 0.04586 to 0.04247, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.99357 to 0.99500, saving model to nextValid_acc.h5\n",
      "Epoch 11/100\n",
      " - 746s - loss: 0.0401 - acc: 0.9888 - val_loss: 0.0195 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00011: loss improved from 0.04247 to 0.04010, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.99500 to 0.99548, saving model to nextValid_acc.h5\n",
      "Epoch 12/100\n",
      " - 745s - loss: 0.0415 - acc: 0.9880 - val_loss: 0.0180 - val_acc: 0.9938\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.04010\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99548\n",
      "Epoch 13/100\n",
      " - 744s - loss: 0.0379 - acc: 0.9887 - val_loss: 0.0240 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00013: loss improved from 0.04010 to 0.03786, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.99548\n",
      "Epoch 14/100\n",
      " - 748s - loss: 0.0379 - acc: 0.9889 - val_loss: 0.0218 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.03786\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.99548\n",
      "Epoch 15/100\n",
      " - 745s - loss: 0.0332 - acc: 0.9902 - val_loss: 0.0159 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00015: loss improved from 0.03786 to 0.03317, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99548\n",
      "Epoch 16/100\n",
      " - 747s - loss: 0.0304 - acc: 0.9914 - val_loss: 0.0184 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00016: loss improved from 0.03317 to 0.03039, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99548\n",
      "Epoch 17/100\n",
      " - 744s - loss: 0.0284 - acc: 0.9917 - val_loss: 0.0215 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00017: loss improved from 0.03039 to 0.02837, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99548\n",
      "Epoch 18/100\n",
      " - 745s - loss: 0.0241 - acc: 0.9928 - val_loss: 0.0167 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00018: loss improved from 0.02837 to 0.02406, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.99548\n",
      "Epoch 19/100\n",
      " - 744s - loss: 0.0239 - acc: 0.9933 - val_loss: 0.0160 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00019: loss improved from 0.02406 to 0.02388, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.99548 to 0.99571, saving model to nextValid_acc.h5\n",
      "Epoch 20/100\n",
      " - 743s - loss: 0.0239 - acc: 0.9930 - val_loss: 0.0162 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.02388\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.99571 to 0.99595, saving model to nextValid_acc.h5\n",
      "Epoch 21/100\n",
      " - 744s - loss: 0.0232 - acc: 0.9933 - val_loss: 0.0183 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00021: loss improved from 0.02388 to 0.02318, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99595\n",
      "Epoch 22/100\n",
      " - 744s - loss: 0.0236 - acc: 0.9933 - val_loss: 0.0167 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.02318\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99595\n",
      "Epoch 23/100\n",
      " - 745s - loss: 0.0217 - acc: 0.9938 - val_loss: 0.0146 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00023: loss improved from 0.02318 to 0.02168, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99595\n",
      "Epoch 24/100\n",
      " - 744s - loss: 0.0216 - acc: 0.9932 - val_loss: 0.0162 - val_acc: 0.9955\n",
      "\n",
      "Epoch 00024: loss improved from 0.02168 to 0.02162, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.99595\n",
      "Epoch 25/100\n",
      " - 743s - loss: 0.0220 - acc: 0.9938 - val_loss: 0.0149 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.02162\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.99595 to 0.99619, saving model to nextValid_acc.h5\n",
      "Epoch 26/100\n",
      " - 744s - loss: 0.0218 - acc: 0.9935 - val_loss: 0.0153 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.02162\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.99619 to 0.99643, saving model to nextValid_acc.h5\n",
      "Epoch 27/100\n",
      " - 743s - loss: 0.0219 - acc: 0.9940 - val_loss: 0.0142 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.02162\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.99643\n",
      "Epoch 28/100\n",
      " - 745s - loss: 0.0200 - acc: 0.9938 - val_loss: 0.0156 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00028: loss improved from 0.02162 to 0.02003, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99643\n",
      "Epoch 29/100\n",
      " - 744s - loss: 0.0187 - acc: 0.9942 - val_loss: 0.0148 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00029: loss improved from 0.02003 to 0.01869, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99643\n",
      "Epoch 30/100\n",
      " - 744s - loss: 0.0189 - acc: 0.9945 - val_loss: 0.0149 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.01869\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.99643\n",
      "Epoch 31/100\n",
      " - 743s - loss: 0.0189 - acc: 0.9947 - val_loss: 0.0148 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.01869\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.99643 to 0.99667, saving model to nextValid_acc.h5\n",
      "Epoch 32/100\n",
      " - 743s - loss: 0.0206 - acc: 0.9939 - val_loss: 0.0145 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.01869\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.99667\n",
      "Epoch 33/100\n",
      " - 745s - loss: 0.0197 - acc: 0.9944 - val_loss: 0.0152 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.01869\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.99667\n",
      "Epoch 34/100\n",
      " - 743s - loss: 0.0193 - acc: 0.9943 - val_loss: 0.0149 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.01869\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.99667\n",
      "Epoch 35/100\n",
      " - 744s - loss: 0.0194 - acc: 0.9945 - val_loss: 0.0148 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.01869\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.99667\n",
      "Epoch 36/100\n",
      " - 744s - loss: 0.0186 - acc: 0.9948 - val_loss: 0.0146 - val_acc: 0.9964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: loss improved from 0.01869 to 0.01864, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.99667\n",
      "Epoch 37/100\n",
      " - 744s - loss: 0.0192 - acc: 0.9943 - val_loss: 0.0145 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.01864\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.99667\n",
      "Epoch 38/100\n",
      " - 745s - loss: 0.0208 - acc: 0.9942 - val_loss: 0.0140 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.01864\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.99667\n",
      "Epoch 39/100\n",
      " - 743s - loss: 0.0190 - acc: 0.9945 - val_loss: 0.0143 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.01864\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.99667\n",
      "Epoch 40/100\n",
      " - 744s - loss: 0.0193 - acc: 0.9946 - val_loss: 0.0147 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.01864\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.99667\n",
      "Epoch 41/100\n",
      " - 744s - loss: 0.0192 - acc: 0.9948 - val_loss: 0.0146 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.01864\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.99667\n",
      "Epoch 42/100\n",
      " - 744s - loss: 0.0186 - acc: 0.9950 - val_loss: 0.0142 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00042: loss improved from 0.01864 to 0.01855, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.99667\n",
      "Epoch 43/100\n",
      " - 746s - loss: 0.0186 - acc: 0.9946 - val_loss: 0.0142 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.01855\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.99667\n",
      "Epoch 44/100\n",
      " - 744s - loss: 0.0180 - acc: 0.9947 - val_loss: 0.0141 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00044: loss improved from 0.01855 to 0.01795, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.99667\n",
      "Epoch 45/100\n",
      " - 744s - loss: 0.0182 - acc: 0.9947 - val_loss: 0.0148 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.01795\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.99667\n",
      "Epoch 46/100\n",
      " - 744s - loss: 0.0182 - acc: 0.9948 - val_loss: 0.0149 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.01795\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.99667\n",
      "Epoch 47/100\n",
      " - 745s - loss: 0.0194 - acc: 0.9944 - val_loss: 0.0147 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.01795\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.99667\n",
      "Epoch 48/100\n",
      " - 744s - loss: 0.0195 - acc: 0.9944 - val_loss: 0.0147 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.01795\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.99667\n",
      "Epoch 49/100\n",
      " - 744s - loss: 0.0197 - acc: 0.9940 - val_loss: 0.0147 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.01795\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.99667\n",
      "Epoch 50/100\n",
      " - 743s - loss: 0.0191 - acc: 0.9939 - val_loss: 0.0149 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.01795\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.99667\n",
      "Epoch 51/100\n",
      " - 744s - loss: 0.0191 - acc: 0.9945 - val_loss: 0.0150 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00051: loss did not improve from 0.01795\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.99667\n",
      "Epoch 52/100\n",
      " - 746s - loss: 0.0179 - acc: 0.9949 - val_loss: 0.0150 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00052: loss improved from 0.01795 to 0.01788, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.99667\n",
      "Epoch 53/100\n",
      " - 744s - loss: 0.0187 - acc: 0.9950 - val_loss: 0.0146 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00053: loss did not improve from 0.01788\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.99667\n",
      "Epoch 54/100\n",
      " - 744s - loss: 0.0203 - acc: 0.9944 - val_loss: 0.0150 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00054: loss did not improve from 0.01788\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.99667\n",
      "Epoch 55/100\n",
      " - 744s - loss: 0.0174 - acc: 0.9949 - val_loss: 0.0152 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00055: loss improved from 0.01788 to 0.01742, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.99667\n",
      "Epoch 56/100\n",
      " - 743s - loss: 0.0199 - acc: 0.9941 - val_loss: 0.0151 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00056: loss did not improve from 0.01742\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.99667\n",
      "Epoch 57/100\n",
      " - 745s - loss: 0.0179 - acc: 0.9946 - val_loss: 0.0152 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00057: loss did not improve from 0.01742\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.99667\n",
      "Epoch 58/100\n",
      " - 744s - loss: 0.0203 - acc: 0.9941 - val_loss: 0.0152 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00058: loss did not improve from 0.01742\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.99667\n",
      "Epoch 59/100\n",
      " - 744s - loss: 0.0180 - acc: 0.9944 - val_loss: 0.0158 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00059: loss did not improve from 0.01742\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.99667\n",
      "Epoch 60/100\n",
      " - 743s - loss: 0.0187 - acc: 0.9948 - val_loss: 0.0149 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00060: loss did not improve from 0.01742\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.99667\n",
      "Epoch 61/100\n",
      " - 743s - loss: 0.0192 - acc: 0.9943 - val_loss: 0.0150 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00061: loss did not improve from 0.01742\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.99667\n",
      "Epoch 62/100\n",
      " - 765s - loss: 0.0169 - acc: 0.9949 - val_loss: 0.0149 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00062: loss improved from 0.01742 to 0.01692, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.99667\n",
      "Epoch 63/100\n",
      " - 748s - loss: 0.0176 - acc: 0.9945 - val_loss: 0.0153 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00063: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.99667\n",
      "Epoch 64/100\n",
      " - 744s - loss: 0.0201 - acc: 0.9945 - val_loss: 0.0150 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00064: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.99667\n",
      "Epoch 65/100\n",
      " - 744s - loss: 0.0190 - acc: 0.9944 - val_loss: 0.0154 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00065: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.99667\n",
      "Epoch 66/100\n",
      " - 744s - loss: 0.0178 - acc: 0.9945 - val_loss: 0.0153 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00066: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.99667\n",
      "Epoch 67/100\n",
      " - 746s - loss: 0.0184 - acc: 0.9952 - val_loss: 0.0153 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00067: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.99667\n",
      "Epoch 68/100\n",
      " - 743s - loss: 0.0188 - acc: 0.9948 - val_loss: 0.0156 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00068: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.99667\n",
      "Epoch 69/100\n",
      " - 743s - loss: 0.0189 - acc: 0.9946 - val_loss: 0.0156 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00069: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.99667\n",
      "Epoch 70/100\n",
      " - 743s - loss: 0.0184 - acc: 0.9949 - val_loss: 0.0154 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00070: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.99667\n",
      "Epoch 71/100\n",
      " - 744s - loss: 0.0169 - acc: 0.9952 - val_loss: 0.0149 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00071: loss improved from 0.01692 to 0.01692, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.99667\n",
      "Epoch 72/100\n",
      " - 746s - loss: 0.0188 - acc: 0.9949 - val_loss: 0.0155 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00072: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.99667\n",
      "Epoch 73/100\n",
      " - 743s - loss: 0.0182 - acc: 0.9949 - val_loss: 0.0154 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00073: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.99667\n",
      "Epoch 74/100\n",
      " - 743s - loss: 0.0183 - acc: 0.9949 - val_loss: 0.0160 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00074: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.99667\n",
      "Epoch 75/100\n",
      " - 744s - loss: 0.0184 - acc: 0.9942 - val_loss: 0.0157 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00075: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.99667\n",
      "Epoch 76/100\n",
      " - 746s - loss: 0.0189 - acc: 0.9941 - val_loss: 0.0158 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00076: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.99667\n",
      "Epoch 77/100\n",
      " - 744s - loss: 0.0182 - acc: 0.9948 - val_loss: 0.0154 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00077: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.99667\n",
      "Epoch 78/100\n",
      " - 744s - loss: 0.0175 - acc: 0.9949 - val_loss: 0.0158 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00078: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.99667\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 744s - loss: 0.0174 - acc: 0.9946 - val_loss: 0.0161 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00079: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.99667\n",
      "Epoch 80/100\n",
      " - 744s - loss: 0.0169 - acc: 0.9951 - val_loss: 0.0159 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00080: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.99667\n",
      "Epoch 81/100\n",
      " - 746s - loss: 0.0180 - acc: 0.9948 - val_loss: 0.0153 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00081: loss did not improve from 0.01692\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.99667\n",
      "Epoch 82/100\n",
      " - 744s - loss: 0.0160 - acc: 0.9953 - val_loss: 0.0156 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00082: loss improved from 0.01692 to 0.01601, saving model to nextLoss.h5\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.99667\n",
      "Epoch 83/100\n",
      " - 806s - loss: 0.0195 - acc: 0.9950 - val_loss: 0.0153 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00083: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.99667\n",
      "Epoch 84/100\n",
      " - 877s - loss: 0.0181 - acc: 0.9949 - val_loss: 0.0157 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00084: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.99667\n",
      "Epoch 85/100\n",
      " - 836s - loss: 0.0188 - acc: 0.9946 - val_loss: 0.0152 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00085: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.99667\n",
      "Epoch 86/100\n",
      " - 822s - loss: 0.0169 - acc: 0.9950 - val_loss: 0.0153 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.99667\n",
      "Epoch 87/100\n",
      " - 862s - loss: 0.0167 - acc: 0.9950 - val_loss: 0.0151 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00087: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.99667\n",
      "Epoch 88/100\n",
      " - 874s - loss: 0.0189 - acc: 0.9947 - val_loss: 0.0148 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.99667\n",
      "Epoch 89/100\n",
      " - 853s - loss: 0.0184 - acc: 0.9945 - val_loss: 0.0153 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.99667\n",
      "Epoch 90/100\n",
      " - 842s - loss: 0.0173 - acc: 0.9951 - val_loss: 0.0151 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00090: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.99667\n",
      "Epoch 91/100\n",
      " - 757s - loss: 0.0189 - acc: 0.9944 - val_loss: 0.0144 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00091: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.99667\n",
      "Epoch 92/100\n",
      " - 813s - loss: 0.0171 - acc: 0.9952 - val_loss: 0.0149 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00092: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.99667\n",
      "Epoch 93/100\n",
      " - 767s - loss: 0.0172 - acc: 0.9953 - val_loss: 0.0153 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00093: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.99667\n",
      "Epoch 94/100\n",
      " - 763s - loss: 0.0163 - acc: 0.9953 - val_loss: 0.0158 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00094: loss did not improve from 0.01601\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.99667\n",
      "Epoch 95/100\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(\n",
    "                aug.flow(trainX, trainY, batch_size=TBS),\n",
    "                validation_data=(validX, validY), \n",
    "                callbacks=[reduce_lr,checkpoint1,checkpoint2], \n",
    "                validation_steps=validX.shape[0]/VBS, \n",
    "                steps_per_epoch=trainX.shape[0]/TBS, \n",
    "                epochs=EPOCHS, \n",
    "                verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy learning curves\n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-Making predictions on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Reshaping the test data from 1D to 2D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv').values\n",
    "test.shape\n",
    "testX = test.reshape(test.shape[0],1,28, 28).astype( 'float32' )\n",
    "X_test = testX/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.array(X_test)\n",
    "X_test=np.transpose(X_test, (0,2, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(X_test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"CNN-DigitRec.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
